{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7f272-efa7-4178-b3ad-a998ed0beddc",
   "metadata": {},
   "source": [
    "FGSM on a neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4a3e2e-0c17-4b79-bfb3-f01690c35b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107ada430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../neat\"))\n",
    "\n",
    "from cppn import *\n",
    "from genome import *\n",
    "from speciation import *\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef0358e-d2fc-4268-bb94-603ed55c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data_tensor = torch.tensor(digits.data, dtype=torch.float32)\n",
    "data_tensor = torch.tensor(digits.data / 16.0, dtype=torch.float32) # Normalize for neat\n",
    "target_tensor = torch.tensor(digits.target, dtype=torch.long)\n",
    "\n",
    "# 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_tensor, target_tensor, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Batch is the full size because there is no backpropogation\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af748ab8-48f4-4e29-a5ab-f5b5a2d7ab3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init stuff\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 8*8\n",
    "output_dim = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = NN(input_dim, output_dim).to(device)\n",
    "model.load_state_dict(torch.load('../models/sklearn_digits_100pop_2000epoch_real95.83.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca41ebc1-c7d9-4494-82f4-9389ee6d84a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.36%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in train_loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(data)  # logits\n",
    "        predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59793b92-5f23-42fe-98c4-efabddfdfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_img(img, label=None):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(img, cmap='gray_r')\n",
    "    if label is not None:\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b765e2e-64e0-4b0c-8743-d9ce5a48b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM\n",
    "\n",
    "# new image = original image + perturbation scalar * neg (gradient with respect to the loss)\n",
    "\n",
    "def FGSM(img, target, scalar=.01):\n",
    "    img = img.clone().view(1, -1).detach().requires_grad_(True)  # Input usually doesnt require grad\n",
    "    y = model(img)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(y, target.view(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    grad = img.grad.data\n",
    "    signed_grad = grad.sign()\n",
    "    mod_img = img + (scalar * signed_grad)\n",
    "    return mod_img.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "558e637d-6e26-4c56-8cde-05560bab6a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor[1232].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "424f07ff-310d-409b-8fb4-75a35b57ffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(data_tensor[1232].view(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5faedb8e-bae7-40c3-8307-37c686c2b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda52f41-ede6-41d8-afed-a3e8901d762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 8]' is invalid for input of size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# modified.shape\u001b[39;00m\n\u001b[32m      5\u001b[39m modified_label = torch.argmax(model(modified))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m plot_img(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m, modified_label)\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[8, 8]' is invalid for input of size 10"
     ]
    }
   ],
   "source": [
    "plot_img(data_tensor[d].view(8, 8), target_tensor[d])\n",
    "\n",
    "modified = FGSM(data_tensor[d], target_tensor[344])\n",
    "# modified.shape\n",
    "modified_label = torch.argmax(model(modified))\n",
    "\n",
    "plot_img(modified.view(8, 8), modified_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0d599-2892-43db-afe4-5e4794faaa74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neat",
   "language": "python",
   "name": "neat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
